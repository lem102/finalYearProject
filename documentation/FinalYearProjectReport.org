#+options: ':nil *:t -:t ::t <:t H:4 \n:nil ^:t arch:headline
#+options: author:t broken-links:nil c:nil creator:nil
#+options: d:(not "LOGBOOK") date:t e:t email:nil f:t inline:t num:t
#+options: p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t
#+options: timestamp:t title:t toc:t todo:t |:t
#+title: Final Year Project Report
#+author: Jacob Leeming
#+language: en
#+select_tags: export
#+exclude_tags: noexport
#+creator: Emacs 27.1 (Org mode 9.3)

#+latex_class: article
#+latex_class_options:
#+latex_header:

#+LATEX_HEADER: \tolerance=1
#+LATEX_HEADER: \emergencystretch=\maxdimen
#+LATEX_HEADER: \hyphenpenalty=10000
#+LATEX_HEADER: \hbadness=10000
#+LATEX_HEADER: \frenchspacing

#+LATEX_HEADER: \usepackage{apacite}
#+LATEX_HEADER: \usepackage{natbib}
#+LATEX_HEADER: \usepackage{minted}
#+latex_header: \bibliographystyle{apacite}

#+latex_header_extra:
#+description:
#+keywords:
#+subtitle:
#+latex_compiler: pdflatex
#+date: \today

* Project Proposal
** Problem Statement

In the world of computer science, and computer programming in general,
there is an abundance of learning materials freely available from which
students can learn how to program, how to use a certain programming language,
how to use a framework for that language, etc.. One area of study that
is not as well developed in terms of learning materials is compiler design.
It would be unfair to say that there is nothing for a beginner to make
use of, however these resources have a tendency to ignore or gloss over
the gory details, advising that tools are used to generate complex parts
of the compiler for them. 

This is good advice, and indeed in a "real world" situation an organisation
that wanted to create a compiler would use these tools as the popular ones
are tried and tested (LLVM, a massive compilation library is used in several
mainstream languages, such as Swift and Rust. Several languages also have
LLVM implementations of their compilers, for example the C/C++ compiler
clang.), and simplify the compiler creation process immensely. However,
if a learner wished to understand what these tools did, they would need
to either read the source code of these tools (this would be difficult,
as some of the projects are massive and very complex.), or read books of
a technical nature, such as Compilers: Principles, Techniques and tools
(henceforth referred to as the Dragon Book). While the Dragon book is an
excellent resource for designing compilers, it is too dense for a learner
who wants to apply any knowledge that can be gleaned from it.

This is the problem. There is an absence of material that shows the learner
that they can create a compiler with only their own code, and without becoming
a computer science professor first!

In order to rectify this problem, I propose the following: 

** Product Description

The product that I will produce at the end of this project is a compiler
for a general purpose programming language of my own creation. The compiler
will be able to compile a program written in said programming language
into assembly language targeting the x86 CPU architecture. The compiler
will be written in a modular, easily understandable way using the Java
programming language. It will be written in this way to encourage learning
about the various stages of compilation. 

As a supplement to the compiler I will also provide a learning plan in
pdf form to demonstrate how the compiler could be used as a learning resource,
including breakdowns of the more important parts of the code base and how
they relate to the ideas featured in the design of compilers, such as tokens,
syntax trees, etc.

** Users or Audience

The users that I imagine would be interested in this project would be anyone
who is interested in the inner workings of a compiler, and how they could
go about creating their own compiler without leaning on other available
tools. As compiler design is quite a technical subject, I would expect
that the users of this project would be at university level or equivalent
in terms of their education in computer science or programmming.

* Background Research
** Necessary Background Material
*** Required Knowledge

To understand the source code aspect of my project, a reader would need
to understand basic programming concepts such as what a statement is, how
basic logic such as if statements and loop statements work, and be decently
familiar with either Java or another mainly object oriented language (for
example, C#). They would also need to understand object oriented concepts,
such as classes, objects and inheritance. A basic understanding of assembly
would also be useful for the later parts of the compiler where we are creating
machine code, but I will be documenting these quite intensely and intend
to make them as simple as possible.

I would also recommend reading the first chapter of Compilers: Principles
techniques and tools (AKA The Dragon Book) \citep{dragon}. This chapter
gives an overview of the various components of a compiler and the different
transformations that the code that is being compiled needs to undergo before
it can be processed by the CPU. An especially useful resource to understand
these concepts is figure 1.7, which can be found on page 7. This figure
shows how the code to be compiled will look through the various stages
of compilation.

Other topics of interest that are located within this chapter are the concepts
of tokens, syntax trees and intermediate representation. These are what
the source code of this project will be attempting to produce and then
use in later parts of the compiler input's journey through the compiler.

*** What is a compiler?

In short, a compiler is a computer program that converts a source program
into machine code that can be executed by a CPU. It does this by taking
its input, a program that is written in a human-readable programming language
and performing multiple actions upon it. As a result of these actions,
an executable program is produced that can be run by the computer.

*** Why do we use compilers?

Back in the 1950's, programmers wrote software in assembly language. This
means that in order to tell the computer to do something, they would have
to write instructions that would change the state of specific bits in order
to do anything. This meant that even doing simple things takes a lot more
lines of code than in higher level programming languages that we have today.
For example, this C program;

#+BEGIN_SRC c
  #include <stdio.h>

  int main()
  {
      printf("Hello, World.");
  }
#+END_SRC

becomes much more complicated in assembly language \citep{assemblyHelloWorld}:

#+BEGIN_SRC asm
  global _start

  section .text

  _start:
    mov rax, 1        ; write(
    mov rdi, 1        ;   STDOUT_FILENO,
    mov rsi, msg      ;   "Hello, world!\n",
    mov rdx, msglen   ;   sizeof("Hello, world!\n")
    syscall           ; );

    mov rax, 60       ; exit(
    mov rdi, 0        ;   EXIT_SUCCESS
    syscall           ; );

  section .rodata
    msg: db "Hello, world!", 10
    msglen: equ $ - msg
#+END_SRC

This meant that programmers were a lot less productive, as they spent a
lot of time doing what we now consider trivial operations, as well as having
to create solutions to complex problems. As a consequence of this, the
price of software exceeded that of the hardware available at the time due
to how complicated and time consuming it was to make even a simple program.

Happily, this was all soon to change. In the 1950s, a man called John Backus
joined IBM as a programmer. The first project he worked on was a program
in machine code to calculate the position of the moon. Because programming
in machine code was so awful, he invented a program called SpeedCoding.
SpeedCoding is essentially a collection of macros that would reduce the
amount of time a programmer would spend on common tasks by running chunks
of code created on the fly based on a few parameters supplied by the program.
This enhanced programmer productivity, but at a cost. If a program using
SpeedCoding was running, then SpeedCoding also need to be running to "interpret"
the fancy SpeedCoding instructions. This consumed a large chunk of the
memory of the computers they had at the time, so it was deemed not practical.

After his experiments with SpeedCoding, Backus was appointed as the manager
of the Programming Research Department at IBM in 1954. During this time,
he assembled a team and developed FORTRAN. FORTRAN was the first widely
used high-level language, and it greatly simplified writing software. It
worked by taking input in the form of a simpler language which abstracted
away many of the complications caused by writing directly in assembly,
and then translated that input into assembly instructions which could then
be run on a compatible computer. This was the first practical use of a
compiler \citep{johnBackus}.

The impact of FORTRAN was massive. Kenneth Thompson, the creator of the
UNIX operating system said "95 percent of the people who programmed in
the early years would never have done it without FORTRAN." \citep{kenThompson}.
It allowed non-programmers to be able to write code, so scientists were
able to write the code for their programs without hiring a programmer to
do it for them, greatly lowering the barrier to entry for computing.

Of course the development of higher level languages continued beyond FORTRAN,
leading to other compiled languages such as C, Java, and many, many more.
These languages have iterated upon each other, gone in different directions
and had different design philosophies. But all of them exist to make it
easier for programmers to write code, and are continually developed to
make it even easier. So we owe a great deal to FORTRAN and to compilers
for making these abstractions.

*** The structure of a compiler

The overall structure of compilers has not changed much since the creation
of FORTRAN I, and the compiler I will create also mostly sticks to the
ideas introduced by it. The structure of a compiler is made up of several
stages:

**** Lexical Analysis

In this first stage, the source code is split into groups of characters
which have meaning called lexemes. For example, this:

#+BEGIN_SRC text
  example = 1 + 3
#+END_SRC

Would be split into the following lexemes:

#+BEGIN_SRC text
  example
  =
  1
  +
  3
#+END_SRC

Each of these lexemes are then used to create a token. Each token has a
value and a type. The variable example is stored in what is called a syntax
table at index 1. The equals sign and the addition sign both have no value,
but they are the type of an assignment operator and an addition operator
respectively. Both of the numbers have the type integer and the value of
1 and 3 respectively. This leaves us with the following tokens.

#+BEGIN_SRC text
  (id, 1)
  (assignment, =)
  (integer, 1)
  (addition, +)
  (integer, 3)
#+END_SRC

**** Syntax Analysis

After the source code has been successfully split into tokens, a syntax
tree needs to be produced using the tokens from the previous phase. The
purpose of this tree is to show how the tokens all relate to each other.
In the tokens that we have from the previous phase, the assignment token
would be the root token of the statement, the identifier before the assignment
and the expression after the assignment would be the children of the assignment
token.

**** Semantic Analysis

After the syntax tree has been created, there needs to be additional analysis
to determine the types of the various symbols referred to in the source
code, and keep this information in the syntax table. Once the types of
the symbols have been determined, a process called type checking begins.
This is where we check that the correct types are used in the correct way.
For example, if we have a string and we attempt to divide it by an integer,
we would want the compiler to throw an error as dividing a word by a number
is obviously not intended.

In some situations, for example if we are multiplying a floating point
number by an integer, we would want the type of a symbol to be converted
to another type to allow the result to be correctly stored within the syntax
table. These sort of conversions are also handled by the semantic analyser.

In addition to the checking of types, we need to check that the usage of
symbols are restricted to the correct scope. For example, if in the source
code we have an if statement in which a variable called test is declared,
we wouldn't want test to be accessable outside of the if statement, as
test would be outside of the scope of the if statement. If source code
was supplied to the compiler that attempted to refer to a variable in such
a way, then we should throw an error.

**** Intermediate Code Generator 

This stage is the final stage of the "front end" of the compiler. Now that
we have the syntax tree of the source code and the complete symbol table
of all symbols used in the source code we can generate what is called intermediate
code. Intermediate code is a sort of pseudo code that needs to have the
following two features, first one being it needs to be easy to produce,
and the other one being it needs to be easy to translate.

A common type of intermediate code is called three address code, which
is where each line of code refers to three or fewer variables. This pseudo
code is essentially the source code distilled into its very basic operations.


This:

#+BEGIN_SRC text
  example = x + y * 3
#+END_SRC

Will become something like this:

#+BEGIN_SRC text
  t1 = y * 3
  t2 = x + t1
  example = t2
#+END_SRC

This code can now be easily translated into an assembly language, as each
line only uses basic operations. But before we do that, there is an additional
stage that we must first put this intermediate code through.

**** Code Optimisation

This stage we look at the intermediate representation produced in the last
step and try to improve its efficiency. We can do this by combining certain
lines of code, so for example:

This:

#+BEGIN_SRC text
  t1 = y * 3
  t2 = x + t1
  example = t2
#+END_SRC

Could become this:

#+BEGIN_SRC text
  t1 = y * 3
  example = x + t1
#+END_SRC

There are many other techniques that can be used to optimise intermediate
representation code that can get quite complicated. Finally, we get to
the last stage:

**** Code Generation

For the code generation stage, we need to generate code in the target language
using the intermediate representation that we have produced from the previous
steps. Exactly what is done here depends on the target language, if we
are targeting machine code then we will need to decide what registers will
hold the variables used in the program. After the variables have been sorted
out, then code in the target language is generated that performs the exact
same operations that were specified in each line of the intermediate code.

**** The Symbol Table

Throughout the process of compilation, a data structure known as the symbol
table is used to store all information about any symbols referred to in
the source code. These symbols tend to be identifiers for variables or
function names. Because we are going to compile the code into a different
target language it is important that for all of the symbols pertaining
to variables, their types and the scope of the variable are correctly stored.
Then for symbols pertaining to functions we must store the required parameters
of the function and the types of those parameters.

All of this information is gathered during the syntax analysis phase and
validated during the semantic analysis phase. The data within the syntax
table is important throughout nearly all the phases of compilation \citep{dragon}.

** Related Work

*** A Compiler for Teaching about Compilers

This paper sounds like it has a comparable spirit to this project in that
it espouses similar ideas regarding how the use of compiler creation tools
effect educational benefits, but the paper discusses a compiler that is
designed in order to teach a course, whereas mine is simply a resource
from which you can see how a compiler could be implemented without the
use of compiler creation tools \citep{compilerForTeachingCompilers}.

The compiler in this course is designed to be very modular, so that a student
on the course could take out a component of the compiler and replace it
with their own. This also means that the student would be able to replace
parts of their own work with the teachers, which could be useful if they
wanted to see how that part of the compiler is supposed to function.

This project and my project are similar in that they both involve creating
a compiler that needs to be modular and simple to understand so that students
can learn the basic concepts of how compilers work from reading the provided
source code. This means that both projects will need to have clean, readable
code.

The projects differ in their purpose, however. My project is simply a supplement
to an existing course, or perhaps just an example to showcase the inputs
and outputs of different steps of compilation. The project described in
the paper is meant to be at the centre of a university module, and is designed
to be extremely modular to the point that students can remove some component
and replace it with their own. Although my compiler will try to be modular
in order to encourage experimentation, it is not the primary focus of my
project, which is to demonstrate that a compiler can be built without needing
lots of theoretical knowledge.

*** A Set Of Tools To Teach Compiler Construction

This paper introduces a set of tools to aid in the teaching of compilers,
as the authors of the paper found that some of the tools commonly used
in compiler construction were either obsolete or lacking in terms of educational
features. One example of how they remedied this is by making use of a modified
GNU bison, which outputs a detailed description of the various states the
parser is in whilst parsing the input tokens. This information was lacking
in the original bison, making it very difficult to find errors in either
the input or the parser code.

My project differs from the tools described in the above paper quite significantly.
In the paper, they still make use of tools to create code which skips over
the gory details. These tools are better for education, which is an improvement,
but I want to stick to just using a single programming language (Java)
in my project. My intention with this is to reveal how a normal student
could create a compiler with out the use of complicated tools and theories,
therefore making the student totally understand the process of compilation
\citep{aSetOfToolsToTeachCompilerConstruction}.

** Professional, Legal Ethical \amp Social Issues
* Project Planning

- User Requirements
- Choice of tools/techniques/approach
  - relevance to degree/course knowledge
- Risk Management
- Product Development Plan

In this section, I will discuss the planning of this project.

** User Requirements

The first and most important part of planning a project is gathering the
user's requirements. I think the most important deliverable of this project
would be the compiler itself, so the main requirement of this project would
be a compiler that can translate code from a high level programming language
into assembly code. 

This compiler has a few sub-requirements; it must be written in a
way that is understandable to a second year computer science student, and
it must be able to show the process that source code goes through on its
journey to becoming assembly language.

The language that the compiler compiles from needs to be sufficiently complicated
so as to illustrate the main issues regarding compilation, such as operator
precedence, correct assembly generation, etc.

** Choice of Tools

*** Programming Language

An important decision I had to make early on is which programming language
should the compiler be written in. I chose to use Java, but considered
two other programming languages, Python and C#.

I thought Python could be a good choice for the compiler due to its prevelance
in eduction as well as its simpler syntax when compared to Java, which
would allow students to be able to better understand the code. However,
upon experimenting with the object oriented side of Python, I realised
this syntactic simplicity was only present as long as the programmer was
writing procedural code. The final nail in the coffin was when I considered
the fact that Python is a dynamically typed language, rather than being
statically typed. Given the nature of my project, I think that a dynamically
typed language would hinder me somewhat, as there will be many custom types
in use at each stage of the compiler. A statically typed language would
allow me to catch trivial bugs at compile time rather than having to waste
time debugging something breaking during runtime.

The other language that I was considering was C#. On the surface, C# is
very similar to Java. C# has many advanced language features, such as a
great deal of syntactic sugar and support for functional programming using
LINQ and lambda expressions, which increase programmer productivity, and
reduces the amount of boiler plate code that has to be written. Unfortunately,
unless you are familiar with these features, and understand what they are
doing, it is all too easy to get confused, and use them blindly without
thinking. It is also likely that students will never have used C# before,
compounding any potential confusion.

I chose Java as the implementation language of the compiler because it
is a very common language, and although its use in industry is gradually
decreasing, it is still the main language used at universities for the
purposes of teaching. Because of this, many students will be familiar with
Java, and it lowers the barrier to entry for reading the code of this project's
compiler. The other main advantage of Java is its great object oriented
features, such as polymorphism and inheritance, whcih allow for very productive
coding.

** Risk Management

In every project, there are risks, and this project is no exception! The
main risk to this project that I can forsee is running out of time before
the central deliverable (the compiler) is completed. As I have no experience
with writing a compiler, or writing assembly, I have no idea how long it
will take to write a given part of the codebase. There is something I can
do to mitigate this risk, however. 

As part of an ideal compiler, there would be a stage where the source code
is checked for correctness, so if a syntactical or semantical error is
found, then the compiler will emit an error message. As this compiler is
not intended for serious use, I can justify skipping over that section
in favour of the others (which have a greater educational value), and coming
back to it later if I have time.

** Product Development Plan

I think I can split the development of the compiler into four main stages:
- The Tokeniser
- The Parser
- The Intermediate Code Generator
- The Assembly Generator

In regards to how much time each stage of the compiler will take to write,
I suspect that the most complicated part of the code base will be the assembly
generator (mostly to do with the presence of assembly). The tokeniser should
be relatively simple, with the parser and the intermediate code generator
coming in somewhere between the tokeniser and the assembly generator. As
each stage of the project relies on the previous, I will need to write
them in order to make sure they work well together.

Considering the difficulty levels of each stage and the order in which
they have to be written, I think this is an appropriate plan:

[[./ganntChart.png]]

* Design
** Product Specification



** models, diagrams, etc.
* Implementation
** skills and knowledge required for development
** implementation details
** testing
* Evaluation
** product evaluation
** project evaluation
*** what did you learn?
*** what competencies/skills did you develop?
*** self-criticism/reflection
* Conclusions
** summary
** future plans
* MISC

** comments

Inline comments within the source code will be kept to a minimum, this
is done to prevent noise when reading the source code. An overview of the
structure of the program will be stored in the README.org file found at
the root of the project. 

\bibliography{bibliography.bib}
